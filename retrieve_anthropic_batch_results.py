#!/usr/bin/env python3
"""
Retrieve results from an already completed Anthropic batch.
Use this when a batch completed but result processing failed.
"""

import os
import sys
import pandas as pd
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

from anthropic_providers import AnthropicSwitchClassifier
from config_system import ConfigManager


def load_environment():
    """Load Anthropic API key."""
    load_dotenv()
    
    api_key = os.getenv('ANTHROPIC_API_KEY')
    if not api_key:
        print("‚ùå Error: ANTHROPIC_API_KEY not found in .env file")
        sys.exit(1)
    
    print("‚úÖ Anthropic API key loaded successfully")
    return api_key


def retrieve_and_process_results(batch_id: str, data_file: str, config_name: str):
    """Retrieve results from completed batch and process them."""
    
    # Load API key and create classifier
    api_key = load_environment()
    classifier = AnthropicSwitchClassifier(api_key=api_key)
    
    # Load original data
    print(f"üìä Loading original data from: {data_file}")
    try:
        original_data = pd.read_csv(data_file)
        print(f"‚úÖ Data loaded: {original_data.shape}")
    except Exception as e:
        print(f"‚ùå Error loading data: {e}")
        sys.exit(1)
    
    # Check batch status first
    print(f"üîç Checking batch status: {batch_id}")
    try:
        batch_info = classifier.provider.client.messages.batches.retrieve(batch_id)
        print(f"Batch status: {batch_info.processing_status}")
        
        if batch_info.processing_status != "ended":
            print(f"‚ùå Batch is not completed yet. Current status: {batch_info.processing_status}")
            return
            
    except Exception as e:
        print(f"‚ùå Error checking batch status: {e}")
        sys.exit(1)
    
    # Retrieve results
    print(f"üì• Retrieving batch results...")
    try:
        # Get batch results
        batch_results = classifier.provider.process_batch_results(batch_id)
        print(f"‚úÖ Retrieved {len(batch_results)} results")
        
        # Reconstruct the original requests metadata for processing
        # We need this to map results back to the original data
        print("üîÑ Reconstructing request metadata...")
        
        # Prepare mock requests metadata (we need this for result processing)
        mock_requests = []
        request_index = 0
        
        for (player_id, category), group in original_data.groupby(['playerID', 'category']):
            sequence_data = group.sort_values('word_index')
            complete_word_sequence = sequence_data['text'].tolist()
            
            if not complete_word_sequence:
                continue
            
            custom_id = f"switch_{config_name}_{request_index:04d}"
            
            mock_request = {
                "custom_id": custom_id,
                "metadata": {
                    "player_id": player_id,
                    "category": category,
                    "total_words": len(sequence_data),
                    "sequence_length": len(complete_word_sequence),
                    "word_sequence": complete_word_sequence,
                    "request_index": request_index,
                    "config_name": config_name
                }
            }
            
            mock_requests.append(mock_request)
            request_index += 1
        
        print(f"‚úÖ Reconstructed {len(mock_requests)} request metadata entries")
        
        # Process results using the existing method
        print("üîÑ Processing results...")
        result_data = classifier.process_batch_results(batch_id, original_data, mock_requests)
        
        # Save results
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f"data_with_switches_{config_name}_retrieved_{timestamp}.csv"
        
        result_data.to_csv(output_file, index=False)
        print(f"‚úÖ Results saved to: {output_file}")
        
        # Save metadata
        config_manager = ConfigManager()
        config = config_manager.get_config(config_name)
        if config:
            additional_info = {
                'retrieved_batch': True,
                'original_batch_id': batch_id,
                'num_results': len(batch_results),
                'num_players': original_data['playerID'].nunique(),
                'categories': list(original_data['category'].unique()),
                'data_shape': list(original_data.shape)
            }
            
            config_manager.save_run_metadata(
                config=config,
                output_file=output_file,
                batch_id=batch_id,
                additional_info=additional_info
            )
        
        # Show summary
        print("\nüìà Results Summary:")
        total_rows = len(result_data)
        rows_with_llm = result_data['switchLLM'].notna().sum()
        llm_switch_rate = result_data['switchLLM'].mean() if rows_with_llm > 0 else 0
        
        print(f"Total rows: {total_rows:,}")
        print(f"Rows with LLM classifications: {rows_with_llm:,}")
        print(f"LLM switch rate: {llm_switch_rate:.3f}")
        
        print(f"\nüéâ Results successfully retrieved from batch {batch_id}!")
        
    except Exception as e:
        print(f"‚ùå Error processing results: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def main():
    """Main function."""
    print("üîÑ Anthropic Batch Results Retriever")
    print("=" * 50)
    
    if len(sys.argv) < 2:
        print("Usage: python retrieve_anthropic_batch_results.py <batch_id> [data_file] [config_name]")
        print("\nExample:")
        print("  python retrieve_anthropic_batch_results.py msgbatch_01QFg7w8w5X9LFDc72C56WuL")
        print("  python retrieve_anthropic_batch_results.py msgbatch_01QFg7w8w5X9LFDc72C56WuL merged_trials_data_unfiltered.csv claude-sonnet-4-switches")
        sys.exit(1)
    
    batch_id = sys.argv[1]
    
    # Try to find data file
    if len(sys.argv) > 2:
        data_file = sys.argv[2]
    else:
        # Try to find data file automatically
        current_dir = Path(".")
        patterns = [
            "filtered_data_for_analysis.csv",
            "*filtered*.csv",
            "merged_trials_data_unfiltered.csv",
            "*.csv"
        ]
        
        data_file = None
        for pattern in patterns:
            files = list(current_dir.glob(pattern))
            if files:
                data_file = str(files[0])
                break
        
        if not data_file:
            print("‚ùå Could not find data file. Please specify it as second argument.")
            sys.exit(1)
    
    # Get config name
    if len(sys.argv) > 3:
        config_name = sys.argv[3]
    else:
        config_name = "retrieved_batch"
    
    print(f"Batch ID: {batch_id}")
    print(f"Data file: {data_file}")
    print(f"Config name: {config_name}")
    print()
    
    retrieve_and_process_results(batch_id, data_file, config_name)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Script interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)